{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "toxicity_in_comments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZloIKTIBQ4ce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all necessary libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import string\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBJiSEthQ4co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data.\n",
        "df = pd.read_csv('comments_with_scores_and_features.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81rtJHszQ4cz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a79e1a82-f6bf-433a-ffa2-2cc919e57c29"
      },
      "source": [
        "# Review column list.\n",
        "df.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'by', 'author', 'time', 'time_ts', 'text', 'parent', 'deleted',\n",
              "       'dead', 'ranking', 'neg', 'neu', 'pos', 'compound', 'tb_polarity',\n",
              "       'tb_subjectivity', 'toxicity'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3pQXAbxQ4c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define target column.\n",
        "y = df['toxicity']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V515uXzTQ4dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp4xXb8aQ4dR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into train and test subsets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], \n",
        "                                                    y, \n",
        "                                                    train_size=0.8, \n",
        "                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5wSdESbQ4db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert comment text to lowercase, remove punctuation, and trim \n",
        "# whitespace.\n",
        "simple_text_train = X_train.str.lower()\n",
        "simple_text_train = simple_text_train.str.replace('[{}]'.format(string.punctuation), '')\n",
        "simple_text_train = simple_text_train.str.replace('\\s+', ' ', regex=True)\n",
        "simple_text_train = simple_text_train.str.strip()\n",
        "\n",
        "simple_text_test = X_test.str.lower()\n",
        "simple_text_test = simple_text_test.str.replace('[{}]'.format(string.punctuation), '')\n",
        "simple_text_test = simple_text_test.str.replace('\\s+', ' ', regex=True)\n",
        "simple_text_test = simple_text_test.str.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLRxoGQaQ4dg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "b7a2d834-57ea-4756-ed32-edce221e92a0"
      },
      "source": [
        "for text in simple_text_train.head():\n",
        "    print(text, '\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "without the safe harbor agreement you can no longer avoid eu privacy regulations by storing the data in the us maybe im missing something here my understanding is that the safe harbour agreement wasnt a mechanism for us companies to avoid eu data protection regulations it was a certification that they did comply with eu data protection particularly in situations where that data was transmitted outside the eu now its gone eu customer data held by us companies will be governed by national data protection laws instead so may end up having to be stored within the eu the us privacy regulations are no longer considered compatible with the eu privacy regulations i dont think they ever were which is why the safe harbour needed to exist in the first place \n",
            "\n",
            "imagine how much a interlispd smalltalk mesacedar workstation would have cost in the 70s versus a plain pdp11 eh if theyd put altos in serial production instead of small batches at a time adding up to 2000 units it wouldnt have been vastly more expensive there was nothing both exotic and wildly expensive about them compared to contemporary pdp11s a graphics console the extras were a mouse chord keyboard network adapter and more memory per person than normal for a pdp11 \n",
            "\n",
            "thanks for the links as the current defacto maintainer of ppi the answer is rather simple pt predates ppi by almost two years httpsmetacpanorgsourceshancockperltidy20021130chan httpsmetacpanorgsourceadamkppi01changes and for the longest time perl was considered unparsable primarily due to the two features of function parens being optional and the argumentslurpiness of function calls being unknowable without introspecting the function reference that ends up being the final one at runtime in the most famous example this can lead to a after a function call being considered either the division operator or the start of a regex with both interpretations resulting in valid perl code it took a while for anyone to come up with a schema in which perl could be parsed while also being roundtrippable it took ppi a while to get there and be stable and meanwhile pt had already become stable itself \n",
            "\n",
            "surely you can give a rough idea \n",
            "\n",
            "disclaimer im a browser engine developer not a frontend or fullstack web developer that is why you have a sane view on the wed dev trenches more is better we are all insane ppl who think adding react to a page will make it spiffier \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KVRZ-pOQ4dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_train = simple_text_train.apply(nlp.tokenizer)\n",
        "tokens_test = simple_text_test.apply(nlp.tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF5RVVjNQ4dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatize; remove stop words.\n",
        "lemmas_train = tokens_train.apply(lambda x: [token.lemma_ for token in x if not token.is_stop])\n",
        "lemmas_test = tokens_test.apply(lambda x: [token.lemma_ for token in x if not token.is_stop])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDNKBsT8Q4d8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f8d05504-81ca-41c0-a5f7-27f7e50485e8"
      },
      "source": [
        "lemmas_train.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1362    [safe, harbor, agreement, long, avoid, eu, pri...\n",
              "7304    [imagine, interlispd, smalltalk, mesacedar, wo...\n",
              "4237    [thank, link, current, defacto, maintainer, pp...\n",
              "3680                                [surely, rough, idea]\n",
              "4780    [disclaimer, be, browser, engine, developer, f...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9WgT-S7Q4eF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "e88dce58-3814-4b2a-e907-91542b3b8f80"
      },
      "source": [
        "# Instantiate vectorizer object.\n",
        "tfidf = TfidfVectorizer(min_df=0.001, max_df=0.999)\n",
        "\n",
        "# Create a vocabulary and get word counts per document.\n",
        "dtm_train = tfidf.fit_transform(lemmas_train.astype(str))\n",
        "dtm_test = tfidf.transform(lemmas_test.astype(str))\n",
        "\n",
        "# Get feature names to use as dataframe column headers.\n",
        "dtm_train_orig = pd.DataFrame(dtm_train.todense(), columns=tfidf.get_feature_names())\n",
        "dtm_test_orig = pd.DataFrame(dtm_test.todense(), columns=tfidf.get_feature_names())\n",
        "\n",
        "# Copy document term matrices.\n",
        "dtm_train = dtm_train_orig.copy()\n",
        "dtm_test = dtm_test_orig.copy()\n",
        "\n",
        "# Preview feature matrix.\n",
        "dtm_train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>101</th>\n",
              "      <th>10k</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>1500</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>1960s</th>\n",
              "      <th>1970s</th>\n",
              "      <th>1980s</th>\n",
              "      <th>1990s</th>\n",
              "      <th>1st</th>\n",
              "      <th>20</th>\n",
              "      <th>200</th>\n",
              "      <th>2000</th>\n",
              "      <th>2007</th>\n",
              "      <th>2008</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>20th</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>28</th>\n",
              "      <th>2nd</th>\n",
              "      <th>30</th>\n",
              "      <th>...</th>\n",
              "      <th>wonderful</th>\n",
              "      <th>wood</th>\n",
              "      <th>word</th>\n",
              "      <th>wordpress</th>\n",
              "      <th>work</th>\n",
              "      <th>worker</th>\n",
              "      <th>workflow</th>\n",
              "      <th>workplace</th>\n",
              "      <th>workstation</th>\n",
              "      <th>world</th>\n",
              "      <th>worldwide</th>\n",
              "      <th>worry</th>\n",
              "      <th>worth</th>\n",
              "      <th>worthless</th>\n",
              "      <th>worthwhile</th>\n",
              "      <th>worthy</th>\n",
              "      <th>would</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>write</th>\n",
              "      <th>writer</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrt</th>\n",
              "      <th>xerox</th>\n",
              "      <th>xss</th>\n",
              "      <th>yard</th>\n",
              "      <th>yc</th>\n",
              "      <th>year</th>\n",
              "      <th>yell</th>\n",
              "      <th>yep</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yield</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtube</th>\n",
              "      <th>zero</th>\n",
              "      <th>zillow</th>\n",
              "      <th>zone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.189891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.21561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.108087</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083457</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159473</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3588 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    10  100  1000  101  10k   11  ...  young  youth  youtube  zero  zillow  zone\n",
              "0  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0    0.0      0.0   0.0     0.0   0.0\n",
              "1  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0    0.0      0.0   0.0     0.0   0.0\n",
              "2  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0    0.0      0.0   0.0     0.0   0.0\n",
              "3  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0    0.0      0.0   0.0     0.0   0.0\n",
              "4  0.0  0.0   0.0  0.0  0.0  0.0  ...    0.0    0.0      0.0   0.0     0.0   0.0\n",
              "\n",
              "[5 rows x 3588 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G80fy3TtQ4eR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_binary = (y_train > 0.7).astype(int)\n",
        "y_test_binary = (y_test > 0.7).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBl1bJHHQ4eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0d2e067-0f54-4543-d165-545bfad2b27e"
      },
      "source": [
        "# Check target distribution.\n",
        "np.bincount(y_train_binary)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7893,   83])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYGrBoEIQ4ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count(docs):\n",
        "    \"\"\"\n",
        "    Helper function for feature selection.\n",
        "    \"\"\"\n",
        "    word_counts = Counter()\n",
        "    appears_in = Counter()\n",
        "    \n",
        "    total_docs = len(docs)\n",
        "\n",
        "    for doc in docs:\n",
        "        word_counts.update(doc)\n",
        "        appears_in.update(set(doc))\n",
        "\n",
        "    temp = zip(word_counts.keys(), word_counts.values())\n",
        "      \n",
        "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
        "\n",
        "    wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
        "    total = wc['count'].sum()\n",
        "\n",
        "    wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
        "        \n",
        "    wc = wc.sort_values(by='rank')\n",
        "    wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
        "\n",
        "    t2 = zip(appears_in.keys(), appears_in.values())\n",
        "    ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
        "    wc = ac.merge(wc, on='word')\n",
        "\n",
        "    wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
        "        \n",
        "    return wc.sort_values(by='rank')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PopEZw5oQ4ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "86215b39-b72c-4b01-b25b-0232591a270d"
      },
      "source": [
        "# Find most common words in toxic comments.\n",
        "toxic_wc_train = count(lemmas_train[y_train_binary.astype(bool)])\n",
        "toxic_wc_train.head(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>appears_in</th>\n",
              "      <th>count</th>\n",
              "      <th>rank</th>\n",
              "      <th>pct_total</th>\n",
              "      <th>cul_pct_total</th>\n",
              "      <th>appears_in_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>not</td>\n",
              "      <td>35</td>\n",
              "      <td>46</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.421687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>fuck</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.010131</td>\n",
              "      <td>0.029548</td>\n",
              "      <td>0.253012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>people</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.010131</td>\n",
              "      <td>0.039679</td>\n",
              "      <td>0.265060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>shit</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.009709</td>\n",
              "      <td>0.049388</td>\n",
              "      <td>0.253012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>like</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.008864</td>\n",
              "      <td>0.058252</td>\n",
              "      <td>0.156627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>s</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.008442</td>\n",
              "      <td>0.066695</td>\n",
              "      <td>0.180723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>amazon</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.007176</td>\n",
              "      <td>0.073871</td>\n",
              "      <td>0.036145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>time</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.006754</td>\n",
              "      <td>0.080625</td>\n",
              "      <td>0.156627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>work</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.006754</td>\n",
              "      <td>0.087379</td>\n",
              "      <td>0.108434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>have</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.006332</td>\n",
              "      <td>0.093710</td>\n",
              "      <td>0.132530</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       word  appears_in  count  rank  pct_total  cul_pct_total  appears_in_pct\n",
              "3       not          35     46   1.0   0.019417       0.019417        0.421687\n",
              "7      fuck          21     24   2.0   0.010131       0.029548        0.253012\n",
              "34   people          22     24   3.0   0.010131       0.039679        0.265060\n",
              "52     shit          21     23   4.0   0.009709       0.049388        0.253012\n",
              "171    like          13     21   5.0   0.008864       0.058252        0.156627\n",
              "56        s          15     20   6.0   0.008442       0.066695        0.180723\n",
              "933  amazon           3     17   7.0   0.007176       0.073871        0.036145\n",
              "40     time          13     16   8.0   0.006754       0.080625        0.156627\n",
              "204    work           9     16   9.0   0.006754       0.087379        0.108434\n",
              "100    have          11     15  10.0   0.006332       0.093710        0.132530"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUiVOiHBQ4em",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "3a934926-df69-4c7e-984d-d6a4e5e4189f"
      },
      "source": [
        "# Find most common words in non-toxic comments.\n",
        "nontoxic_wc_train = count(lemmas_train[~y_train_binary.astype(bool)])\n",
        "nontoxic_wc_train.head(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>appears_in</th>\n",
              "      <th>count</th>\n",
              "      <th>rank</th>\n",
              "      <th>pct_total</th>\n",
              "      <th>cul_pct_total</th>\n",
              "      <th>appears_in_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>not</td>\n",
              "      <td>2984</td>\n",
              "      <td>4872</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.019678</td>\n",
              "      <td>0.019678</td>\n",
              "      <td>0.378057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>people</td>\n",
              "      <td>1485</td>\n",
              "      <td>2272</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.009177</td>\n",
              "      <td>0.028855</td>\n",
              "      <td>0.188141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>like</td>\n",
              "      <td>1439</td>\n",
              "      <td>1900</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.007674</td>\n",
              "      <td>0.036530</td>\n",
              "      <td>0.182313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>s</td>\n",
              "      <td>1246</td>\n",
              "      <td>1590</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.006422</td>\n",
              "      <td>0.042952</td>\n",
              "      <td>0.157861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>think</td>\n",
              "      <td>1196</td>\n",
              "      <td>1508</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.006091</td>\n",
              "      <td>0.049043</td>\n",
              "      <td>0.151527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>thing</td>\n",
              "      <td>985</td>\n",
              "      <td>1287</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.005198</td>\n",
              "      <td>0.054241</td>\n",
              "      <td>0.124794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>work</td>\n",
              "      <td>887</td>\n",
              "      <td>1245</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.005029</td>\n",
              "      <td>0.059270</td>\n",
              "      <td>0.112378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>time</td>\n",
              "      <td>880</td>\n",
              "      <td>1147</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.004633</td>\n",
              "      <td>0.063903</td>\n",
              "      <td>0.111491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>use</td>\n",
              "      <td>826</td>\n",
              "      <td>1088</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.068297</td>\n",
              "      <td>0.104650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>have</td>\n",
              "      <td>887</td>\n",
              "      <td>1078</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>0.072651</td>\n",
              "      <td>0.112378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       word  appears_in  count  rank  pct_total  cul_pct_total  appears_in_pct\n",
              "7       not        2984   4872   1.0   0.019678       0.019678        0.378057\n",
              "223  people        1485   2272   2.0   0.009177       0.028855        0.188141\n",
              "371    like        1439   1900   3.0   0.007674       0.036530        0.182313\n",
              "206       s        1246   1590   4.0   0.006422       0.042952        0.157861\n",
              "34    think        1196   1508   5.0   0.006091       0.049043        0.151527\n",
              "233   thing         985   1287   6.0   0.005198       0.054241        0.124794\n",
              "217    work         887   1245   7.0   0.005029       0.059270        0.112378\n",
              "49     time         880   1147   8.0   0.004633       0.063903        0.111491\n",
              "250     use         826   1088   9.0   0.004395       0.068297        0.104650\n",
              "27     have         887   1078  10.0   0.004354       0.072651        0.112378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr4Ea8rMQ4eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make comparison table.\n",
        "comp = pd.merge(toxic_wc_train[['word', 'appears_in_pct']], \n",
        "                nontoxic_wc_train[['word', 'appears_in_pct']], \n",
        "                how='outer', on='word', suffixes = ('_toxic', '_nontoxic'))\n",
        "\n",
        "comp = comp.fillna(0)\n",
        "\n",
        "comp['diff'] = abs(comp['appears_in_pct_toxic'] - comp['appears_in_pct_nontoxic'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hi348mOQ4et",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "7c7718e3-e852-4607-c3c1-9147109f7ca2"
      },
      "source": [
        "# Visualize words with the biggest frequency difference between comment\n",
        "# categories.\n",
        "top_15 = comp.sort_values(by='diff', ascending=False).head(15)\n",
        "top_15.sort_values(by='appears_in_pct_toxic',\n",
        "                   ascending=False).plot.bar(x='word',\n",
        "                                             y=['appears_in_pct_toxic',\n",
        "                                                'appears_in_pct_nontoxic']);"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAErCAYAAADQckjCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZwU5bX/8c9h0UFRBEFvkChoFEWYARzAqyLgitGgRg0u+AOJGjSImp/ekGvcSEgwxhU3UMElbhGvV+ISlQARfi7siLuIBFGjBBUJirKc3x9P9dAzDjM9XdXDdPF9v17zmu7qqtPP9MycqnrqeU6ZuyMiIunVaEs3QERECkuJXkQk5ZToRURSToleRCTllOhFRFKuyZZuQFWtW7f29u3bb+lmiIgUlblz5/7L3dtU91qDS/Tt27dnzpw5W7oZIiJFxcz+sbnX1HUjIpJySvQiIimnRC8iknINro9epJisW7eO5cuXs3bt2i3dFNlKlJSU0K5dO5o2bZrzNkr0IjEsX76cHXbYgfbt22NmW7o5knLuzsqVK1m+fDkdOnTIeTt13YjEsHbtWnbeeWcleakXZsbOO+9c5zNIJXqRmJTkpT7l8/emRC8iknLqoxdJUPuRTyUab+mYYxONJ1unojmibz/yqWq/RKS4nH322bzxxhsFf58bb7yRr776qsZ1fve73+Udf/LkyYwZMybv7etT0SR6EWmY1q9fX6f177rrLjp16lSg1mxS6EQ/YMAARo4cmff29UmJXqTInXDCCRxwwAHsv//+jB8/HoDmzZtz8cUXs//++3P44YezYsUKAPr27cuFF15I165d6dy5M7NmzQJgzZo1DB06lJ49e9KtWzeeeOIJAJYuXUrv3r3p3r073bt358UXXwRg+vTp9O7dmwEDBtCpUyfWrFnDscceS1lZGZ07d+aRRx7ZbHv79u1bUc+qefPmXHbZZZSVlXHggQfyySefbHa7IUOGMGzYMMrLy9lnn3148sknAdiwYQOXXHIJnTt3prS0lLFjx3LzzTfz0Ucf0a9fP/r161dtvJEjR/L111/TtWtXzjjjDACuv/56OnfuTOfOnbnxxhsBuOGGGxg6dCgAixYtonPnznz11Vfcc889DB8+HIBPPvmEE088kbKyMsrKyio+p4ZCffQiRW7ChAm0atWKr7/+mh49enDSSSexZs0aysvLueGGGxg1ahRXX301t9xyCwBfffUVCxYs4IUXXmDo0KG89tprjB49msMOO4wJEybwxRdf0LNnT4444gh22WUXnn/+eUpKSnj33Xc57bTTKpL0vHnzeO211+jQoQOPPfYYbdu25amnQnfqqlWrcmr7mjVrOPDAAxk9ejT/9V//xZ133smvf/3rza6/dOlSZs2axXvvvUe/fv1YvHgxEydOZOnSpSxYsIAmTZrw2Wef0apVK66//nqmTZtG69atq401ZswYbrnlFhYsWADA3LlzmThxIq+88gruTq9evejTpw8XXnghffv25fHHH2f06NGMGzeO7bbbrlKsESNG0KdPHx5//HE2bNjAv//975x+/vqiI3qRInfzzTdXHBF/8MEHvPvuuzRq1IiBAwcCMGjQIGbOnFmx/mmnnQbAoYceypdffskXX3zBc889x5gxY+jatSt9+/Zl7dq1LFu2jHXr1nHOOefQpUsXTjnllEp96z179qyYtNOlSxeef/55fvnLXzJjxgxatGiRU9u32WYbjjvuOAAOOOAAli5dWuP6P/nJT2jUqBF77703e+65J2+99RZTpkzhZz/7GU2ahOPWVq1a5fbBVTFz5kxOPPFEtt9+e5o3b86Pf/xjZsyYQaNGjbjnnns488wz6dOnDwcffPB3tp06dSrnnXceAI0bN875568vOqIXKWLTp09nypQpvPTSS2y33XYVSbqq7LHXVcdhmxnuzmOPPUbHjh0rvXbVVVex6667snDhQjZu3EhJSUnFa9tvv33F43322Yd58+bx9NNP8+tf/5rDDz+cK664otb2N23atKI9jRs3rrW/v7q214d3332X5s2b89FHH9XL+yVNiV4kQfU9HHLVqlW0bNmS7bbbjrfeeouXX34ZgI0bNzJp0iROPfVUHnzwQQ455JCKbR555BH69evHzJkzadGiBS1atODoo49m7NixjB07FjNj/vz5dOvWjVWrVtGuXTsaNWrEvffey4YNG6ptx0cffUSrVq0YNGgQO+20E3fddVdBft5HH32UwYMH8/7777NkyRI6duzIkUceybhx4+jXr1+lrpsddtiB1atXb7brBsKOZt26dTRt2pTevXszZMgQRo4cibvz+OOPc//997Nq1SpGjBjBCy+8wPDhw5k0aRInn3xypTiHH344t99+OxdddFFF101DOqpX141IEevfvz/r169nv/32Y+TIkRx44IFAONqeNWsWnTt3ZurUqZWOrktKSujWrRvDhg3j7rvvBuDyyy9n3bp1lJaWsv/++3P55ZcDcP7553PvvfdSVlbGW2+9VekoPtuiRYvo2bMnXbt25eqrr66xnz2O3XffnZ49e3LMMcdwxx13UFJSwtlnn83uu+9OaWkpZWVlPPjggwCce+659O/ff7MXYzPrlJaWcsYZZ9C9e3eGDBlCz5496dWrF2effTbdunXj4osv5uc//zn77LMPd999NyNHjuTTTz+tFOemm25i2rRpdOnShQMOOKBeho/Whbl77SuZ9QduAhoDd7n7mCqv/wI4G1gPrACGuvs/otc2AIuiVZe5+4Ca3qu8vNyru8PU5sbMa0KJbElvvvkm++2335Zuxnc0b9682guCffv25Y9//CPl5eVboFXxDBkyhOOOO+47R9Nbo+r+7sxsrrtX+4uttevGzBoDtwJHAsuB2WY22d2zd1nzgXJ3/8rMzgP+AAyMXvva3bvW/UepH4XcgVQXWzsmEalvufTR9wQWu/sSADN7GDgeqEj07j4ta/2XgUFJNlJE6mZzw/umT59eb2048cQTef/99ystu+aaazj66KNr3G706NE8+uijlZadcsop3HPPPXm3pVevXnzzzTeVlt1///106dIl75jFJJdEvxvwQdbz5UCvGtb/KfBM1vMSM5tD6NYZ4+7/W3UDMzsXOBdCH5yIFL/HH388r+0uu+wyLrvsskTb8sorryQar9gkOurGzAYB5UCfrMV7uPuHZrYnMNXMFrn7e9nbuft4YDyEPvok2yQisrXLZdTNh8D3s563i5ZVYmZHAJcBA9y94hzJ3T+Mvi8BpgPdYrRXRETqKJdEPxvY28w6mNk2wKnA5OwVzKwbMI6Q5D/NWt7SzLaNHrcGDiarb19ERAqv1q4bd19vZsOBZwnDKye4++tmNgqY4+6TgWuB5sCj0Uy1zDDK/YBxZraRsFMZU2W0jki6XJXwJJmrcqsZI1KTnCZMufvT7r6Pu+/l7qOjZVdESR53P8Ldd3X3rtHXgGj5i+7exd3Lou93F+5HEZFi0JDq0Sdl6dKlFRO18nHFFVcwZcqUBFtUmWbGikgsxVyPPilxE/2oUaM44ogjEmxRZUr0IkVO9ejzq0df0/svXbqUww47jNLSUg4//HCWLVtW0YYRI0Zw0EEHseeeezJp0iQg1LafMWMGXbt25YYbbmDt2rWcddZZdOnShW7dujFtWphqdPzxx3PfffcBMG7cuIo6+EOGDKmINXv2bA466CDKysro2bMnq1ev3mz7c6VEL1LkJkyYwNy5c5kzZw4333wzK1eurKhH//rrr9OnTx+uvvrqivUz9ehvu+22ihtqZOrRz5o1i2nTpnHppZeyZs2ainr08+bN45FHHmHEiBEVcebNm8dNN93EO++8w1//+lfatm3LwoULee211+jfv39Obc/Uo1+4cCGHHnood955Z43rZ+rRP/XUUwwbNoy1a9cyfvz4inr0r776KmeccQYjRoygbdu2TJs2rSLJ1uX9L7jgAgYPHlwpXsbHH3/MzJkzefLJJyvuMDVmzBh69+7NggULuPjii7n11lsxMxYtWsRDDz3E4MGDK9o6atQoZsyYwXXXXcfYsWMrtefbb79l4MCB3HTTTSxcuJApU6bQrFmznD7LmijRixQ51aPPvx795t7/pZde4vTTTwfgzDPPrPT5nXDCCTRq1IhOnTpt9gxk5syZDBoUCgTsu+++7LHHHrzzzjvsuuuujBo1in79+nHdddd9p61vv/023/ve9+jRowcAO+64Y8XPFYfKFIsUMdWjj1ePvq7vD7DttttWPM6lKGRVixYtYuedd67X2vZK9CJJqufhkKpHH68e/eYcdNBBPPzww5x55pk88MAD9O7du8b1M++V0bt3bx544AEOO+ww3nnnHZYtW0bHjh2ZNWsWzzzzDPPnz6dPnz4cddRRFWdFAB07duTjjz9m9uzZ9OjRg9WrV9OsWbPYR/VK9CJFrH///txxxx3st99+dOzY8Tv16H/729+yyy67VLo4mqlHv27dOiZMmACEevQXXXQRpaWlbNy4kQ4dOvDkk09y/vnnc9JJJ3HffffRv3//GuvRX3rppTRq1IimTZty++23F+TnzdSj//LLLyvVo3/nnXcoLS2ladOmnHPOOQwfPryiHn2mr74uxo4dy1lnncW1115LmzZtmDhxYo3rl5aW0rhxY8rKyhgyZAjnn38+5513Hl26dKFJkyYVBdnOOeccJk6cSNu2bbnuuusYOnQoU6dOrYizzTbb8Mgjj3DBBRfw9ddf06xZM6ZMmULz5s3r/Flly6kefX2q73r0KlMscageff1RPfpN6lqPXhdjRURSTl03IimkevSVqR69iMTi7rFHf6SR6tEXRj7d7eq6EYmhpKSElStX5vXPJ1JX7s7KlSsrDXPNhY7oRWJo164dy5cvrygxIFJoJSUltGvXrk7bKNGLxNC0adNK46BFGiJ13YiIpJwSvYhIyinRi4iknBK9iEjKKdGLiKScEr2ISMop0YuIpJwSvYhIyinRi4iknBK9iEjKKdGLiKScEr2ISMop0YuIpJwSvYhIyinRi4iknBK9iEjK5ZTozay/mb1tZovNbGQ1r//CzN4ws1fN7G9mtkfWa4PN7N3oa3CSjRcRkdrVmujNrDFwK3AM0Ak4zcw6VVltPlDu7qXAJOAP0batgCuBXkBP4Eoza5lc80VEpDa5HNH3BBa7+xJ3/xZ4GDg+ewV3n+buX0VPXwYyNzQ8Gnje3T9z98+B54H+yTRdRERykUui3w34IOv58mjZ5vwUeKYu25rZuWY2x8zm6CbLIiLJSvRirJkNAsqBa+uynbuPd/dydy9v06ZNkk0SEdnq5ZLoPwS+n/W8XbSsEjM7ArgMGODu39RlWxERKZxcEv1sYG8z62Bm2wCnApOzVzCzbsA4QpL/NOulZ4GjzKxldBH2qGiZiIjUkya1reDu681sOCFBNwYmuPvrZjYKmOPukwldNc2BR80MYJm7D3D3z8zsN4SdBcAod/+sID+JiIhUq9ZED+DuTwNPV1l2RdbjI2rYdgIwId8GiohIPJoZKyKSckr0IiIpp0QvIpJySvQiIimX08XYBu2qFtUsW1X/7RARaaB0RC8iknJK9CIiKadELyKSckr0IiIpp0QvIpJySvQiIimnRC8iknJK9CIiKadELyKSckr0IiIpp0QvIpJySvQiIimnRC8iknJK9CIiKadELyKSckr0IiIpp0QvIpJySvQiIimnRC8iknJK9CIiKadELyKSckr0IiIpp0QvIpJySvQiIimnRC8iknI5JXoz629mb5vZYjMbWc3rh5rZPDNbb2YnV3ltg5ktiL4mJ9VwERHJTZPaVjCzxsCtwJHAcmC2mU129zeyVlsGDAEuqSbE1+7eNYG2iohIHmpN9EBPYLG7LwEws4eB44GKRO/uS6PXNhagjSIiEkMuXTe7AR9kPV8eLctViZnNMbOXzeyE6lYws3OjdeasWLGiDqFFRKQ29XExdg93LwdOB240s72qruDu49293N3L27RpUw9NEhHZeuSS6D8Evp/1vF20LCfu/mH0fQkwHehWh/aJiEhMuST62cDeZtbBzLYBTgVyGj1jZi3NbNvocWvgYLL69kVEpPBqTfTuvh4YDjwLvAn82d1fN7NRZjYAwMx6mNly4BRgnJm9Hm2+HzDHzBYC04AxVUbriIhIgeUy6gZ3fxp4usqyK7IezyZ06VTd7kWgS8w2iohIDJoZKyKSckr0IiIpp0QvIpJySvQiIimnRC8iknJK9CIiKadELyKSckr0IiIpp0QvIpJySvQiIimnRC8iknJK9CIiKadELyKSckr0IiIpp0QvIpJySvQiIimnRC8iknJK9CIiKZfTrQSlYWk/8qlqly8dc2w9t0REioGO6EVEUk6JXkQk5ZToRURSToleRCTllOhFRFJOiV5EJOWU6EVEUk6JXkQk5TRhSipoIpZIOumIXkQk5ZToRURSToleRCTlckr0ZtbfzN42s8VmNrKa1w81s3lmtt7MTq7y2mAzezf6GpxUw0VEJDe1JnozawzcChwDdAJOM7NOVVZbBgwBHqyybSvgSqAX0BO40sxaxm+2iIjkKpcj+p7AYndf4u7fAg8Dx2ev4O5L3f1VYGOVbY8Gnnf3z9z9c+B5oH8C7RYRkRzlkuh3Az7Ier48WpaLnLY1s3PNbI6ZzVmxYkWOoUVEJBcN4mKsu49393J3L2/Tps2Wbo6ISKrkkug/BL6f9bxdtCwXcbYVEZEE5JLoZwN7m1kHM9sGOBWYnGP8Z4GjzKxldBH2qGiZiIjUk1oTvbuvB4YTEvSbwJ/d/XUzG2VmAwDMrIeZLQdOAcaZ2evRtp8BvyHsLGYDo6JlIiJST3KqdePuTwNPV1l2Rdbj2YRumeq2nQBMiNFGERGJoUFcjBURkcJRohcRSTklehGRlFOiFxFJOSV6EZGUU6IXEUk53UpQ6kV1tylM4haFuv2hSO10RC8iknJK9CIiKadELyKSckr0IiIpp0QvIpJySvQiIimnRC8iknJK9CIiKacJUyLVKORErPqcPNbQJ6UV22dRrHRELyKSckr0IiIpp0QvIpJySvQiIimnRC8iknJK9CIiKadELyKSckr0IiIpp0QvIpJymhkrIpKjYpwlDEr06XJVi2qWrar/dohIg6KuGxGRlFOiFxFJOSV6EZGUyynRm1l/M3vbzBab2chqXt/WzB6JXn/FzNpHy9ub2ddmtiD6uiPZ5ouISG1qvRhrZo2BW4EjgeXAbDOb7O5vZK32U+Bzd/+BmZ0KXAMMjF57z927JtxuERHJUS5H9D2Bxe6+xN2/BR4Gjq+yzvHAvdHjScDhZmbJNVNERPKVS6LfDfgg6/nyaFm167j7emAVsHP0Wgczm29mfzez3tW9gZmda2ZzzGzOihUr6vQDiIhIzQp9MfZjYHd37wb8AnjQzHasupK7j3f3cncvb9OmTYGbJCKydckl0X8IfD/rebtoWbXrmFkToAWw0t2/cfeVAO4+F3gP2Cduo0VEJHe5JPrZwN5m1sHMtgFOBSZXWWcyMDh6fDIw1d3dzNpEF3Mxsz2BvYElyTRdRERyUeuoG3dfb2bDgWeBxsAEd3/dzEYBc9x9MnA3cL+ZLQY+I+wMAA4FRpnZOmAjMMzdPyvEDyIiItXLqdaNuz8NPF1l2RVZj9cCp1Sz3WPAYzHbKCIiMWhmrIhIyinRi4iknBK9iEjKKdGLiKScEr2ISMrpDlOSTrrblkgFHdGLiKScjuildjo6FilqOqIXEUk5JXoRkZRTohcRSTklehGRlFOiFxFJOSV6EZGUU6IXEUk5jaMXka1DdfNBYKuYE6IjehGRlFOiFxFJOSV6EZGUU6IXEUk5JXoRkZRTohcRSTklehGRlFOiFxFJOSV6EZGUU6IXEUk5lUAQkYZlKy5VUCg6ohcRSTkd0dc3Ha1IWuim8UVDiV4kzXRgIeSY6M2sP3AT0Bi4y93HVHl9W+A+4ABgJTDQ3ZdGr/0K+CmwARjh7s8m1vpC0j+IiGxpCeWhWhO9mTUGbgWOBJYDs81ssru/kbXaT4HP3f0HZnYqcA0w0Mw6AacC+wNtgSlmto+7b6hTKyWdinFnWqjuimL8LKRo5HJE3xNY7O5LAMzsYeB4IDvRHw9cFT2eBNxiZhYtf9jdvwHeN7PFUbyXkmm+iEgD0MCvV5i717yC2clAf3c/O3p+JtDL3YdnrfNatM7y6Pl7QC9C8n/Z3f8ULb8beMbdJ1V5j3OBc6OnHYG36/AztAb+VYf10xq3kLGLLW4hYytu4WMXW9xCxq5L3D3cvU11LzSIi7HuPh4Yn8+2ZjbH3csTblLRxS1k7GKLW8jYilv42MUWt5Cxk4qbyzj6D4HvZz1vFy2rdh0zawK0IFyUzWVbEREpoFwS/WxgbzPrYGbbEC6uTq6yzmRgcPT4ZGCqhz6hycCpZratmXUA9gZmJdN0ERHJRa1dN+6+3syGA88ShldOcPfXzWwUMMfdJwN3A/dHF1s/I+wMiNb7M+HC7Xrg5wUYcZNXl08K4xYydrHFLWRsxS187GKLW8jYicSt9WKsiIgUN9W6ERFJOSV6EZGUU6IXEUm5ok30ZrZdwvGsmmXbJhS7Qy7L8oh7Si7LpGEyswtzWbY1MLMfmVnR5qOGrug+WDM7yMzeAN6KnpeZ2W0JhL67yvs0B55OIC7AY9Usm1TNsrr6VY7LcmJmi8zs1Wq+FpnZqzHamf0e/2Nmxyb9T21mf8tlWZ6x789lWR4GV7NsSL7BzKxVTV/5NxPM7Mc1fcWJHRkIvGtmfzCzfROIB4CZ7WlmfzGzf5nZp2b2hJntmVDsQ8zsrOhxmyQO3rJidzezEWZ2gZl1jxuvQcyMraMbgKOJxvK7+0IzOzSBuMvN7DZ3P9/MWgJPAXfGCRj9we4PtKjyz7AjUBIj7jHAD4HdzOzmKnHX5xsXOC7Gtrm6DTgLuNnMHgUmuntdSl5UYmYlwHZA6+j3ljkz2xHYLW5jI/tXec/GhEqteTGz04DTgQ5mlj0nZQfC8OR8zQWc8BnsDnwePd4JWAbESUQ/quE1B/4nRmzcfZCZ7QicBtxjZg5MBB5y99UxQj9IKMp4YvT8VOAhQomWvJnZlUA5oWTLRKAp8Cfg4Dhxo9hXAKew6TOdaGaPuvtv8w7q7kX1BbwSfZ+ftWxhQrH/ANxBmCR2UgLxjif8EayMvme+bgYOihG3jHA0+I/oe+brx0DLhD6LPYAjosfNgB0S/j22AIYBHwAvEpJ/0zziXAi8D3wDLIkevw8sBIbHbOOvgNWEneeX0ePV0e/z9zE/276E4n59sr66A00S+GzvBH6Y9fwYYFySv79CfQE7AxcBS4FngHeBC2LEe7WaZbHzBbCAsBOdX9N75Rn7baAk63kz4O04MYtuHL2ZTQKuB24h7JUvBMrd/dQ842UfaRtwOWH27l8B3D3WkUr0Hv/p7olX7DSzpu6+rgBxzyEUmWvl7nuZ2d7AHe5+eELxdwYGAWcCHwEPAIcAXdy9b54xL3D3sUm0r5rYv3f3vLvE6puZLXL3LrUtq2PMX9T0urtfn2/sKP4Aws7+B4R7W9zr7p9G1+LecPf2dYyX6ar6JeHM5mHCmcdAwsFQrN+nmc1y955mNs/du5vZ9sBL7l4aJ24Uexpwort/ET3fCfgfdz8s75hFmOhbE26CcgQhMT8HXOjuK/OMN7GGl93dh+YTN4r9X+7+BzMbS/gjqxp8RL6xo/gHEyqE7kHohrMQ1mP1QZrZAkI56VfcvVu0LFaiyIr9OOF0937gHnf/OOu1WAWczOwgoD1ZXZLufl/+ra0UewCQ6SKc7u5Pxog1090PMbPVVP67yPz+dozRVMzsWWAGoSsB4AzgUHc/OkbMK2t63d2vzjd2FP9e4G53f6Ga1w539zpdbzGz99nUjVVVEv8jlxBKuhwJ/B4YCjyYxMGGmf0v0AN4nvAzHEk4+FwO+eWNokv0xcTMfuTufzGz6i664e73xoz/FnAxoW+2orREvju9rLivuHsvM5vv7t0sFKqbl9DRyg/d/ekqy7b1cM+COHHvB/YinFJnPguPuzONYv+esON7IFp0GjDb3f87buxCiI5mr2TTjukF4Gp3j9P/L1WY2ZHAUYSdybPu/nxCcavNFxn55I2iSfSbOyrOSODo+F7CmUHmdKklcF2cI/pCyyTkAsT9A/AF8H+AC4DzCafPlyUQe567d69tWR5x3wQ6eQH+oKMRR13dfWP0vDGhbzaJHV9jYFcqn4Usixu3UMxsH+B2YFd372xmpcAAz/NCYTVnNRUvkczZzXbAL4Dd3f3cqBuyY5wzsmJUTKNu5hQ4fmkmyQO4++dm1i2JwNE/xyV8t1shrz63rOFW08zsWsLV+YojYnefl3djg5GE20MuAn5GGGZ6V5yAZvYfhFEwzaLPNXt0TBJzIl4D/gP4uLYV87QTm0bEbOa+f3VjZhcQjrw/ATZGix3IawdiZje6+0Vm9heq7yockG9bs9wJXAqMi2K+amYPAnklenffIYE21WQi4Yz3oOj5h8CjQF6JvtA7pug99iZ0B3Uia3RenO6mokn0VU9XoqFY7vGGXmVrZGYt3f3zKH4rkvt8HiWM5rmLrC6WGK6r8jy7X9uBvC/aALj7RjP7E/CCxxj6WMXRhDHi7QjtzyT6L4EkukBaA2+Y2Swq7/SSSG6/B+ZHF8mM0CUyMoG4FxKOLmN1tWXJjO3/Y0LxqrOdu8+yyvML4wzpBcDM9gKWu/s3ZtaXsLO7L/vgK097ufvAaEgr7v6V2XcnR+aqHnZMEHZOVxKGkvcjXKSONe+kaBJ9hpmVEz6IHcJT+wIY6u5zY4a+DngpGttthLr6o2PGzFjv7rcnFAt375dUrOpEFx6vBbYhjPXuCoyKkzSjHfW9mQvUVd4viYkmVyUQo1ru/pCZTSdcIAP4pbv/M4HQHwCJ3Vg08z/g7n+3cO+IfQk7/rfd/duE3uZfUVJ2AAu3Gk3iLOoxoNzMfkAozfsEYQz8D2PG/dbMmrGpvXuRdSAQh5mVAb2jpy+4eyKTCoFm7v43MzN3/wdwlZnNBa7IN2DR9NFnRP2lP3f3GdHzQ4DbEuov7cSmo+Gp7v5GTV8I8wgAAA1XSURBVOvnEC8zxGsE8CnwOJWPNmNdHNvMkLdVwFx3XxAj7lzC5zC9AKNuquujn+vueU9AyoqzB7C3u0+J+mYbxznjM7N93f0t28zMxHy7yLJ+b/sTRiA9ReW/i7hDFY8lnEG+Rzho6QD8zN2fiRM3ir0nIREfRBi2+D5wRpSQ4sTNDFO8FFjr7mMzgwFixj0S+DWhG+Q5woSmIe4+PWbcC4Fz2DSp6URgfEKjbl4kDDeeBEwldDeNcfeO+cYsuiN6YEMmyQO4+0wzS+LUcXfg32TdPcvMdo95YSx7piKEvs3sPWvcqdjl0ddfoufHAa8CwyzMpPvDZres2Tp3X1XlDDfWEYEVaJZwVvyKsf+E0Te7EZJdnLH//5fwz1y1qwzidZFlTv+XRV/bRF9JuQ7o5+6LoeIo9inCBKS4PiScUU8jfNZfEibrjYoZd13UvTKYTbNwm8aMSRTvKULSXEIYcJHETbx/CvRy9zUAZnYNYQJcEnM5LiRctxoB/IbQfVPjSJzaFGOi/7uZjSNMY85MgJieOeqKcSHyKTYls2aEo6C3qTL9vS7cvQOAmf0E+Ku7f2lmlxNmQP4m37hZ2gHd3f3f0ftcSfg5DiXsZPJN9K+b2elA4+jC0AjC7NU4OhJ2RDtReTr9akIyjevnRGP/Adz9XTPbJU5Adz8n+p5oV1l1Y84t1P5p7u5fJvAWqzNJPrKE8Dkn4QnCiKx5hMluSTmLMFN6tLu/H3XnJVFP6G5C98qRhAOA+Wb2grvfFDOuUfl62waqH7Nft6BhFNZAd7+EcOB5VtyYUJxdN9NqeNnzHclSzft0B85397MTiPWqu5dG3Uy/IVwsuyLu0MhoHH0Xj2bHWqi2udDd983ntNfM7nf3M83sv4HtyRojDPzG3dfGaW/0HoWaJZz42H+rpViXx5w1HY1WGUZIErMJZzc3ufu1MePeTphE92fCwcsphDOHKRCv3Wb2mrt3jtO++hYlzx6EI+NhwNfuHqtwWtT9NpjQHQtwAmEC4I1x4kaxX3b3A+PGyVZ0R/SFvhCZ9T7zzCypMeqZPf+xwJ3u/pSZ5V+gaJMHgFfM7Ino+Y+ABy1Mx87n+sIBZtaWcJbUj8pdFtsBeSf6rIuwp2dGQGSLOw+CcKb334Thm0cSxv7/pZZtapM589iF0Cc9NXrej3CGE7c8RqfoLO8MQrfKSMKZWKxET+gK+4RQPwdgBeEs9UfEL0D2opl1cfdF8ZpYmW2ayVpJnCGFUdy/EQ5aXiLMFu7h7p/GiRm163oz+zubipid5e7z48aNzLdQ7O5RYE3We+b9eyu6RG9mLag86+/vhBEhsUYvVLmw2YhQnTCpU9MPo+6mI4FroiPv2GV63f03ZvYMm/7Yhrl7Zr7BGXmEvAP4G+HaQfa8BSP8E8b5p3sz+l6o+RCJj/1390wJ2ucISfnj6Pn3gHvixI40NbOmhKPBW9x9nYWqjbFk2p0kM1tE+BtoApxlZksIF5Az48fjDobIHiJcQjgLiVVaOfIq4X+5M2Ggwhdm9pK7f51A7AWEEUdNIJFrehklhMJ52b0TsXbQxdh18xhhckxmXP2ZQJm751UTO6u74gvCuFUI44KXAo8l1F2xHdAfWBT1HX+P0OXyXJ7xdoyOBKv9R0hgNM/t7n5enBhpYmZvuvt+Wc8bAa9nL8sz7ghC0a2FhLO93YE/uXvvGjesPe5Eqj86jlO3aY+aXo876mYz75nIaKwo1g6EeRyXAP/h7rFuKmSVJ7tl+ueT2OEVZJZ+MSb6Be7etbZldYj3BqFA2l8JpWMriZs0C8HMniSchm8g7JAqXiKBgk2FZAnPEs6Kexzh+kfVAm9JzFS8hVDA6qFo0UBgsbtfEDd2Ne/VxN1jjSIzs5OynpYQhv59lED3WMFUGcLaiHCEf567l8WMO5xwMfYAwv/KDGCGu0+tabsc4i4mjLpJarJbduzvXF+LO9S06LpugK/N7BB3nwlgoYJjnNOwTHdFB5LvrigIdz8Owk6q2C6Mkfws4YwbCfX4F3nCRy/uPjy6MJs50h7v7o/XtE1NNjP/IVuscfTuXumOZmb2EDAzTsx6kH09KHNG/ZME4pYQPs+5cXegVSQ62a2KxGfpF2OiP48wwzJTb+RzYtx+zd1vJtztqBi7K+aaWQ93n72lG1IHic4SzvIB8FrSST4juhAW+94EkfqYRp9tb8IF5QarUIMs3D3RchBZO+klhGHdiU52i2TP0odwvSLWLP2i67rJsFDrhoTGHRelaHjlDwh3mlpDgv2ESbPCzxLuQei6+TsJ/eNZgevGF0o17f0n8KuqR/oNSaEGWSTNClyXP+t9kp2lX2yJ3sx2BX4HtHX3Y6IP5D/d/e5aNk2dzV0gK8SFsbis+htBVPzxJTCM7jnCBJNFbKoEmdg/XpKs8n1+v6Mh96UXStKDLOpTwpPdCqIYE/0zhCnYl7l7WTQxZr4nUIdFCm9zs4Q9ZmnlYprIYwW4sUSV+H/zKrd9rG5ZQ5L0IItCK9Rkt0Ipxj761u7+ZzP7FYC7rzezJC/qSWH9Ovr9HUI4Nf0j4UYWcSenPW1mR+U7ZLU+xU3km2NmJYSJba2jIXnZNf93K8R7JijpQRaFVqjJbgVRjIl+jYWbS2fKjh5I4a5+S/IKNUv4POASM/sGWEcD70eHinIe1Y13z3eo6c+Ai4C2hKSTGTm2mmSKbRVS9iALI9zkZcgWbVHNCjLZrVCKMdH/glBhck8z+39AG0LteCkOhZolXN8jWZJwSdbjEuAkYtzEw0OhrpvM7ArgxirdY4nXF0qSh7LaZUU0yGIcYQjoQuCF6HpZg21zMfbRlwDDCXcsWk1UGjSJGaxSeEnPEq4Su5TvTsRKakhkvTCzWe7eM2aMghTRKwQzG+Tuf9rc3IKEhivWiyQmuxVKMR7R30fYc/4uen46oZzpKVusRZIzd/+KrPHoUf2Y2HcoMrMJhNvPvU7l+6822ERfpYRFZjZoEvejLVT3WCFsH30vqjMyCzcemUg42LwL6Ebop2+Q14iKMdF3dvdOWc+nRWUMZOt2YJW/i2KQuTENbJoN+tME4hake6wQ3H2chTLCX7r7DbVu0HAMdfebzOxooCVhOOj9NNBE3yB/+bWYF12ABcBCKeFCVUSU4vFSNKeimHQCbiX0875GGL2RxN/yTwj3EDg6KozVinB3swbJ3TcA3yld3cBlRjT9ELjf3V/PWtbgFGMf/ZuEuxVlyoHuTrgT1Hoa6KxQKTwz60O4SP9Pki2fWzBm9mdCN+QD0aLTgZ3cfavrhjSzGwi3DnyEyjXYY82vKJSoQuhuhBpZZUBjwj2WE6m2mbRiTPT1Xi5VGr6omuAv+O7M2Ab79xAVpetU27KtgVV/5ziPW9W0UKLZsF0JO6dtgdbAbp7AzcELoej66BvyP65sUSvcfXLtqzUo88zsQHd/GbbubshCFTUroKGEm3i3I9yA5ECSuzl44oou0YtsxvxoWvpfqFzUrMGNurFNd2tqSrg137Lo+R7AW1uybVtKEdawupBwH9qX3b2fme3LppGADY4SvaRFM0KCPyprWUMdXnnclm5AA3QPUQ2r6Pk7hP76hpro17r7WjPDzLZ197fMrOOWbtTmKNFLKngB7pNaKOp+rFax1bBabmY7Af8LPG9mnxPKhTdISvSSCmbWjtA/mrlR+gzCfTeXb7lWSR0UVQ0rdz8xenhVdCG5BeF2pA1S0Y26EamOmT0PPEiYtAIwCDjD3Y/ccq2SXEX3jB0LdCbMKWgDnOzur27RhqVEMU6YEqlOG3ef6O7ro697CMlCisNewDHAQYTJXu+iHofEKNFLWqw0s0Fm1jj6GgSs3NKNkpxdHlWsbAn0A24j3KdAEqBEL2kxlDD1/5+EImkn07DrmUtl3ynEBmyzBduTKkr0khajgMHu3sbddyEk/gZ3v1jZrEwhtoGEu4U12EJsxUgfpKRFqbt/nnni7p8RSsdKcSiqQmzFRhc7JC0amVnLTLKPar3r77tIFOo+BRLoH0HS4jpCqeJHo+enAKO3YHtEGgyNo5fUiOqjZKodTnV33ZBGBCV6EZHU08VYEZGUU6IXEUk5JXqRhJnZEDO7ZUu3QyRDiV4kJjNrvKXbIFITJXrZqpnZpWY2Inp8g5lNjR4fZmYPmNlpZrbIzF4zs2uytvu3mV1nZguB/zSzs8zsHTObxaZSySINghK9bO1mAL2jx+VAczNrGi17B7iGMGSzK9DDzE6I1t0eeMXdy4D3COUWDgYOAba6m3tLw6ZEL1u7ucABZrYj4VaELxESfm/gC2C6u69w9/XAA8Ch0XYbgMeix72y1vuWcAs8kQZDiV62au6+DnifUOnyRcIRfj/gB8DSGjZd6+4N+VZ3IhWU6EVCcr8EeCF6PAyYD8wC+phZ6+iC62nA36vZ/pVovZ2jbp9T6qfZIrlRohcJyf17wEvu/gmwFpgRFdYaCUwDFgJz3f2JqhtH611F6Pb5f8Cb9dRukZyoBIKISMrpiF5EJOWU6EVEUk6JXkQk5ZToRURSToleRCTllOhFRFJOiV5EJOX+P1QRIjUvKRvsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13325ER5Q4ey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7051287a-87db-4822-f0f2-77c850958fb5"
      },
      "source": [
        "# Generate feature wordlist from comparison table.\n",
        "autogen_wordlist = comp.sort_values(by='diff', ascending=False).head(229)['word']\n",
        "list(autogen_wordlist)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fuck',\n",
              " 'shit',\n",
              " 'shitty',\n",
              " 'people',\n",
              " 'feel',\n",
              " 'idiot',\n",
              " 'bullshit',\n",
              " 'stupid',\n",
              " 'hell',\n",
              " 'seriously',\n",
              " 'right',\n",
              " 'asshole',\n",
              " 'crap',\n",
              " 'web',\n",
              " 'comment',\n",
              " 'man',\n",
              " 'different',\n",
              " 'ugly',\n",
              " 'care',\n",
              " 'read',\n",
              " 'damn',\n",
              " 'time',\n",
              " 'honest',\n",
              " 'not',\n",
              " 'yes',\n",
              " 'character',\n",
              " 'way',\n",
              " 'abuse',\n",
              " 'terrible',\n",
              " 'year',\n",
              " 'hate',\n",
              " 'begin',\n",
              " 'new',\n",
              " 'human',\n",
              " 'want',\n",
              " 'say',\n",
              " 'mean',\n",
              " 'interest',\n",
              " 'change',\n",
              " 'page',\n",
              " 'search',\n",
              " 'idiotic',\n",
              " 'website',\n",
              " 'datum',\n",
              " 'product',\n",
              " 'backwards',\n",
              " 'come',\n",
              " 'know',\n",
              " 'real',\n",
              " 'entire',\n",
              " 'god',\n",
              " 'case',\n",
              " 'prime',\n",
              " 'use',\n",
              " 'matt',\n",
              " 'criminal',\n",
              " 'buy',\n",
              " 'job',\n",
              " 'tell',\n",
              " 'fix',\n",
              " 'think',\n",
              " 'state',\n",
              " 'font',\n",
              " 'ui',\n",
              " 'googles',\n",
              " 'big',\n",
              " 'tv',\n",
              " 'black',\n",
              " 'error',\n",
              " 'help',\n",
              " 'call',\n",
              " 'complain',\n",
              " 'stuff',\n",
              " 'cost',\n",
              " 'apple',\n",
              " 'count',\n",
              " 'sorry',\n",
              " 'sure',\n",
              " 'user',\n",
              " 'support',\n",
              " 'app',\n",
              " 'death',\n",
              " 'edit',\n",
              " 'etc',\n",
              " 'problem',\n",
              " 'country',\n",
              " 'little',\n",
              " 'probably',\n",
              " 'deal',\n",
              " 'find',\n",
              " 'happen',\n",
              " 'microsoft',\n",
              " 'look',\n",
              " 'like',\n",
              " 'leave',\n",
              " 'language',\n",
              " 'idea',\n",
              " 'expect',\n",
              " 'understand',\n",
              " 'society',\n",
              " 'poor',\n",
              " 'provide',\n",
              " 'go',\n",
              " 'ask',\n",
              " 'asocial',\n",
              " 'blacklivesmatter',\n",
              " 'hermit',\n",
              " 'amazon',\n",
              " 'bitch',\n",
              " 'mauro',\n",
              " 'pretty',\n",
              " 'ditto',\n",
              " 'target',\n",
              " 'include',\n",
              " 'stop',\n",
              " 'child',\n",
              " 'public',\n",
              " 'exactly',\n",
              " 'term',\n",
              " 'spit',\n",
              " 'try',\n",
              " 'issue',\n",
              " 'information',\n",
              " 'source',\n",
              " 'youth',\n",
              " 'safari',\n",
              " 'constructive',\n",
              " 's',\n",
              " 'miss',\n",
              " 'skin',\n",
              " 'smell',\n",
              " 'cop',\n",
              " 'frustration',\n",
              " 'suppose',\n",
              " 'rest',\n",
              " 'attractive',\n",
              " 'similar',\n",
              " 'sense',\n",
              " 'discovery',\n",
              " 'business',\n",
              " 'assume',\n",
              " 'low',\n",
              " 'word',\n",
              " 'true',\n",
              " '3',\n",
              " 'place',\n",
              " 'guy',\n",
              " 'lean',\n",
              " 'eg',\n",
              " 'reason',\n",
              " 'animal',\n",
              " 'transition',\n",
              " 'index',\n",
              " 'linus',\n",
              " 'small',\n",
              " 'shut',\n",
              " 'vw',\n",
              " 'campaign',\n",
              " 'css',\n",
              " 'guess',\n",
              " 'actually',\n",
              " 'override',\n",
              " 'render',\n",
              " 'cancer',\n",
              " 'require',\n",
              " 'mouse',\n",
              " 'cheat',\n",
              " 'to',\n",
              " 'early',\n",
              " 'mac',\n",
              " 'send',\n",
              " 'exclude',\n",
              " 'test',\n",
              " 'world',\n",
              " 'screw',\n",
              " 'car',\n",
              " 'have',\n",
              " 'service',\n",
              " 'arm',\n",
              " 'firefox',\n",
              " 'claim',\n",
              " 'defend',\n",
              " 'wide',\n",
              " 'straight',\n",
              " 'designer',\n",
              " 'burn',\n",
              " 'file',\n",
              " 'limit',\n",
              " 'list',\n",
              " 'google',\n",
              " 'agree',\n",
              " 'argument',\n",
              " 'murder',\n",
              " 'flag',\n",
              " 'simple',\n",
              " 'actual',\n",
              " 'make',\n",
              " 'hand',\n",
              " 'eye',\n",
              " 'tiny',\n",
              " 'suck',\n",
              " 'twice',\n",
              " '1',\n",
              " 'rarely',\n",
              " 'javascript',\n",
              " 'wall',\n",
              " 'mistake',\n",
              " 'perspective',\n",
              " 'allow',\n",
              " 'encourage',\n",
              " 'feature',\n",
              " 'andor',\n",
              " 'fine',\n",
              " 'forget',\n",
              " 'logic',\n",
              " 'internet',\n",
              " 'difference',\n",
              " 'especially',\n",
              " 'damage',\n",
              " 'security',\n",
              " 'organization',\n",
              " 'street',\n",
              " 'free',\n",
              " 'supply',\n",
              " 'group',\n",
              " 'display',\n",
              " 'young',\n",
              " '10',\n",
              " 'late']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6r7VzmxQ4e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature wordlist without stop words.\n",
        "autogen_wordlist = ['fuck',\n",
        "                    'shit',\n",
        "                    'shitty',\n",
        "                    'people',\n",
        "                    'feel',\n",
        "                    'idiot',\n",
        "                    'bullshit',\n",
        "                    'stupid',\n",
        "                    'hell',\n",
        "                    'seriously',\n",
        "                    'right',\n",
        "                    'asshole',\n",
        "                    'crap',\n",
        "                    'web',\n",
        "                    'comment',\n",
        "                    'man',\n",
        "                    'different',\n",
        "                    'ugly',\n",
        "                    'care',\n",
        "                    'read',\n",
        "                    'damn',\n",
        "                    'time',\n",
        "                    'honest',\n",
        "                    'not',\n",
        "                    'yes',\n",
        " 'character',\n",
        " 'way',\n",
        " 'abuse',\n",
        " 'terrible',\n",
        " 'year',\n",
        " 'hate',\n",
        " 'begin',\n",
        " 'new',\n",
        " 'human',\n",
        " 'want',\n",
        " 'say',\n",
        " 'mean',\n",
        " 'interest',\n",
        " 'change',\n",
        " 'page',\n",
        " 'search',\n",
        " 'idiotic',\n",
        " 'website',\n",
        " 'datum',\n",
        " 'product',\n",
        " 'backwards',\n",
        " 'come',\n",
        " 'know',\n",
        " 'real',\n",
        " 'entire',\n",
        " 'god',\n",
        " 'case',\n",
        " 'prime',\n",
        " 'use',\n",
        " 'matt',\n",
        " 'criminal',\n",
        " 'buy',\n",
        " 'job',\n",
        " 'tell',\n",
        " 'fix',\n",
        " 'think',\n",
        " 'state',\n",
        " 'font',\n",
        " 'ui',\n",
        " 'googles',\n",
        " 'big',\n",
        " 'tv',\n",
        " 'black',\n",
        " 'error',\n",
        " 'help',\n",
        " 'call',\n",
        " 'complain',\n",
        " 'stuff',\n",
        " 'cost',\n",
        " 'apple',\n",
        " 'count',\n",
        " 'sorry',\n",
        " 'sure',\n",
        " 'user',\n",
        " 'support',\n",
        " 'app',\n",
        " 'death',\n",
        " 'edit',\n",
        " 'etc',\n",
        " 'problem',\n",
        " 'country',\n",
        " 'little',\n",
        " 'probably',\n",
        " 'deal',\n",
        " 'find',\n",
        " 'happen',\n",
        " 'microsoft',\n",
        " 'look',\n",
        " 'like',\n",
        " 'leave',\n",
        " 'language',\n",
        " 'idea',\n",
        " 'expect',\n",
        " 'understand',\n",
        " 'society',\n",
        " 'poor',\n",
        " 'provide',\n",
        " 'go',\n",
        " 'ask',\n",
        " 'amazon',\n",
        "  'pretty',\n",
        " 'target',\n",
        " 'include',\n",
        " 'stop',\n",
        " 'child',\n",
        " 'public',\n",
        " 'exactly',\n",
        " 'term',\n",
        " 'spit',\n",
        " 'try',\n",
        " 'issue',\n",
        " 'information',\n",
        " 'source',\n",
        " 'youth',\n",
        " 'safari',\n",
        " 'constructive',\n",
        " 'miss',\n",
        " 'skin',\n",
        " 'smell',\n",
        " 'cop',\n",
        " 'frustration',\n",
        " 'suppose',\n",
        " 'rest',\n",
        " 'attractive',\n",
        " 'similar',\n",
        " 'sense',\n",
        " 'discovery',\n",
        " 'business',\n",
        " 'assume',\n",
        " 'low',\n",
        " 'word',\n",
        " 'true',\n",
        " 'place',\n",
        " 'guy',\n",
        " 'lean',\n",
        " 'eg',\n",
        " 'reason',\n",
        " 'animal',\n",
        " 'transition',\n",
        " 'index',\n",
        " 'linus',\n",
        " 'small',\n",
        " 'shut',\n",
        " 'vw',\n",
        " 'campaign',\n",
        " 'css',\n",
        " 'guess',\n",
        " 'actually',\n",
        " 'override',\n",
        " 'render',\n",
        " 'cancer',\n",
        " 'require',\n",
        " 'mouse',\n",
        " 'cheat',\n",
        " 'to',\n",
        " 'early',\n",
        " 'mac',\n",
        " 'send',\n",
        " 'exclude',\n",
        " 'test',\n",
        " 'world',\n",
        " 'screw',\n",
        " 'car',\n",
        " 'have',\n",
        " 'service',\n",
        " 'arm',\n",
        " 'firefox',\n",
        " 'claim',\n",
        " 'defend',\n",
        " 'wide',\n",
        " 'straight',\n",
        " 'designer',\n",
        " 'burn',\n",
        " 'file',\n",
        " 'limit',\n",
        " 'list',\n",
        " 'google',\n",
        " 'agree',\n",
        " 'argument',\n",
        " 'murder',\n",
        " 'flag',\n",
        " 'simple',\n",
        " 'actual',\n",
        " 'make',\n",
        " 'hand',\n",
        " 'eye',\n",
        " 'tiny',\n",
        " 'suck',\n",
        " 'twice',\n",
        " 'rarely',\n",
        " 'javascript',\n",
        " 'wall',\n",
        " 'mistake',\n",
        " 'perspective',\n",
        " 'allow',\n",
        " 'encourage',\n",
        " 'feature',\n",
        " 'andor',\n",
        " 'fine',\n",
        " 'forget',\n",
        " 'logic',\n",
        " 'internet',\n",
        " 'difference',\n",
        " 'especially',\n",
        " 'damage',\n",
        " 'security',\n",
        " 'organization',\n",
        " 'street',\n",
        " 'free',\n",
        " 'supply',\n",
        " 'group',\n",
        " 'display',\n",
        " 'young',\n",
        " '10',\n",
        " 'late']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlpqD9paQ4fA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86cb7a82-16ec-4f17-a8af-60b90cf4edea"
      },
      "source": [
        "len(autogen_wordlist)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFCNtvY_Q4fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtm_train = dtm_train_orig[autogen_wordlist]\n",
        "dtm_test = dtm_test_orig[autogen_wordlist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TToO_6iiQ4fM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zir0Ajv0Q4fQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(keras.layers.Dense(512, input_dim=220, activation='relu'))\n",
        "model.add(keras.layers.Dense(256, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJUaTv_jQ4fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5noUSwzQ4fe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7484ceb1-db0f-4180-b417-591211ff2177"
      },
      "source": [
        "# Fit model.\n",
        "model.fit(dtm_train, y_train_binary, epochs=25, \n",
        "          class_weight = {0: 0.010406, 1: 0.989594},\n",
        "          validation_split=0.2, \n",
        "          verbose=False)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2f0e01e240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6PB8bHxQ4fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "065e8e8c-17ea-4e8e-f3a6-c1a8a268c98e"
      },
      "source": [
        "# Make predictions.\n",
        "nn_train_pred = model.predict(dtm_train)\n",
        "nn_test_pred = model.predict(dtm_test)\n",
        "pd.DataFrame(nn_train_pred).describe()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.976000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.480660e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.191232e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.574896e-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.415649e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.472731e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.067579e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "count  7.976000e+03\n",
              "mean   3.480660e-02\n",
              "std    1.191232e-01\n",
              "min    4.574896e-23\n",
              "25%    5.415649e-09\n",
              "50%    3.472731e-06\n",
              "75%    1.067579e-03\n",
              "max    1.000000e+00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwhQN7G6Q4fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate metrics on training dataset.\n",
        "train_accuracy = accuracy_score(y_train_binary, np.rint(nn_train_pred))\n",
        "train_recall = recall_score(y_train_binary, np.rint(nn_train_pred))\n",
        "train_precision = precision_score(y_train_binary, np.rint(nn_train_pred))\n",
        "\n",
        "# Calculate metrics on test dataset.\n",
        "test_accuracy = accuracy_score(y_test_binary, np.rint(nn_test_pred))\n",
        "test_recall = recall_score(y_test_binary, np.rint(nn_test_pred))\n",
        "test_precision = precision_score(y_test_binary, np.rint(nn_test_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz5EqgSBQ4fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "889bd8d2-e080-4590-c13e-f4366a3f899b"
      },
      "source": [
        "# Display metrics for training dataset.\n",
        "print(f'Train accuracy: {train_accuracy:.4f}')\n",
        "print(f'Train recall: {train_recall:.4f}')\n",
        "print(f'Train precision: {train_precision:.4f}', '\\n')\n",
        "\n",
        "# Display metrics for test dataset.\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')\n",
        "print(f'Test recall: {test_recall:.4f}')\n",
        "print(f'Test precision: {test_precision:.4f}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.9967\n",
            "Train recall: 0.7952\n",
            "Train precision: 0.8800 \n",
            "\n",
            "Test accuracy: 0.9875\n",
            "Test recall: 0.1000\n",
            "Test precision: 0.2222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1aLjQSpQ4fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "ca28ff91-f284-4254-af0c-31e49ba3fa39"
      },
      "source": [
        "for text in X_test[np.rint(nn_test_pred).squeeze().astype(bool)]:\n",
        "    print(text, '\\n')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The author mentions working on Safari. Perhaps writing code to deal with other people's crap has something to do with her views. \n",
            "\n",
            ">  You well and truly are a piece of shit. You can't comment like this here. We've banned this account. \n",
            "\n",
            "Really means a lot. If you ever need a confidence boost though you should checkout 3000[0], I hear that developer is fucking killing it. [0]localhost:3000 \n",
            "\n",
            "That's what I had people do. \n",
            "\n",
            "A link to this gist really should go in the OP by 'whoishiring. It's damn useful. \n",
            "\n",
            "If England hadn't kicked off the industrial revolution it might have taken another few centuries to start and you'd be shitting in a hole in the ground in the dark right now. So be grateful for the huge gift they gave all of us. \n",
            "\n",
            "Just tiny :P \n",
            "\n",
            ">  These threads always fucking suck on HN. Please don't post things like that to HN. They only make threads suck worse. \n",
            "\n",
            "If you want to render an element with transparency, you have to seperate it from the page and render it yourself with ctx.drawWindow(window, x, y, dx, dy, \"transparent\") to a canvas \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45h6lVYJQ4fv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "a65cf0d7-dbeb-4fac-a1d2-b0c04a8b181e"
      },
      "source": [
        "for text in X_test[y_test_binary.astype(bool)]:\n",
        "    print(text, '\\n')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Once you take money from investors, you have both a legal and a moral responsibility to them. It's important to remember that selling equity is really selling something, just like selling a product. You can't sell something, take somebody's money, and then just not deliver. What you are selling to investors, generally, is return on investment. The real problem comes in because founders and VCs have different understandings of \"grow fast\". There will come choices that have different levels of risk. VCs always want you to take the high-risk, high-reward path, because they have a portfolio company and are looking for the few really big winners. You, on the other hand, are trying to build something (team, community, product, etc), and so you will favor slower but safer growth. I guess in theory you could sell VCs on a high-growth approach and then turn around and say, \"Ha ha, fuck you, we're going to keep your money and try to grow modestly.\" But a) VCs are way better at their game than you are, so they're hard to fool, and b) then you're an asshole, which is bad on its own and also has consequences for future relationships (and future funding). Plus, if you're in a VC-fundable space, you'll probably have competitors who are also taking money, and they'll be able to outspend you on future rounds. \n",
            "\n",
            "> There are lab rats (whose hormones/genetics have been fucked with) that can literally die of starvation while remaining nearly spherical with excess fat. I bet there aren't. You'll need to cite that claim. \n",
            "\n",
            "Yeah, and also: Who gives a shit? It's the convention they chose, just adapt to it and get over it, or program in a different language. People who like to complain about PHP are rarely the same people who use it every day. \n",
            "\n",
            "Really means a lot. If you ever need a confidence boost though you should checkout 3000[0], I hear that developer is fucking killing it. [0]localhost:3000 \n",
            "\n",
            "As as society, we're all agitated about dinner because we're trained to be by billions in ad spending. Part of that is a self loathing of one of the key elements of the dinner meal -- culture. Nothing is good enough. My sister is a good example of this. She picked up a crazy, pain in the ass fad diet, has two kids and high powered corporate gig. Her husband is in a similar gig. The kids are in care from 7-7. So yeah, even buying a vegan, glueten free burrito is a pain in the ass. I worry about her, as she's going to have an anxiety attack someday. \n",
            "\n",
            "It's overstepping Facebook's bounds. While legal, it's rather rude and just shows what a shitty service they are: don't trust them with your info. At best, it's a mismatch between what Facebook thinks it is and what users are led to believe. Though, in practise, it's doubtful that it's actually company policy to do this. It's most likely the result of crappy support departments, overloaded with tons of requests. (Users are mostly idiots, so most tickets are of poor quality, and it leads to being aggressive in \"resolving\" tickets, even when the user is fine and in the right.) \n",
            "\n",
            "Easy fix 1 - Vote on the god damn weekend. I can't vote because my boss won't give me time off is the sort of shit that should have been on the scrap heap alongside slavery. Less easy fix 2 - make voting compulsory, with a small fine, like $20/$40 for not showing up to vote. Remember I said showing up, not actually voting, since you can simply cast a blank ballot and then leave having done nothing just as if you didn't vote. \n",
            "\n",
            "Well, a real-life example would contain both disrespect  and  information about the mistakes, and how to do better.  Something more like, 'How could you possibly be so stupid as to use the same memory location to store the car's current radio station and the desired fuel-injection rate, controlled only by a flag in another piece of memory? Didn't it occur to you that someone working on the entertainment system code might never even think of checking for a flag related to speed & safety? Dear God, Smith, do you realise how many people you could have killed? I can only hope that your other mistakes have prevented idiots like you from being born and placed into positions of trust, you sorry misbegotten excuse for an engineer!' Harsh, but I bet Smith would remember that moment well, and be more careful in the future. Or he might quit, and never write automotive-safety-impacting code again. \n",
            "\n",
            "I'm not sure what people find \"beautiful\" or \"touching\" in this story. A man is wracked by guilt over what he has done to the point of deciding to end his life, but then he forgets all about it as soon as a pretty girl gives him attention. Inasmuch as it is believable, this is a story about how all our lofty notions of justice, honor, purpose etc. are just bullshit, and it's really all about fucking, consuming and keeping those genes alive. Matter over mind, humanity revealed as a mere dusting on thought over the throbbing mass of limbic functions. It is depressing. Its only redeeming quality is the fact that it's obviously fake. \n",
            "\n",
            "There is already a tinychat (and the existing tinychat are scumbags) so a name change might be useful. \n",
            "\n",
            "> When everything is communicated in exactly the same \"business professional\" tone, you have effectively reduced the bit depth. That Linus calls any attempt at civility \"bourgeois mores\" or something like that doesn't make it so. No one is calling for the same \"business professional\" tone. Just for basic civility. You can be a  little  rude, just don't go overboard. > The way you deal with things is by being logical and having supporting evidence, but I don't believe communities have to be for everyone and work for everyone. Again, this is the response I'd expect if someone called for mandatory uniforms. Here someone is just asking them to be itsy-bitsy-slightly less dickish. To tone down their dickishness. To go from being total dicks to being normal dicks. Ah, but who decides what is a normal, acceptable amount of dickishness? This is actually quite simple: common sense, combined with listening to what members of the community say (sprinkled with a well deserved apology here and there). And when common sense doesn't cut it any more, there is a need for rules. Namely, the exact same way every reasonably functioning society that wished to be anything less than a total asshole-heaven has done since the dawn of civilization has done it. \n",
            "\n",
            "Um, no offense, why? They crushed all the technical bookstores because they didn't have to pay sales tax.  Their customer service beyond cheap refunds is abysmal.  They understand how hard it is to distinguish between stuff that is only serviced through them, but choose not to fix it.  And Bezos is  famous  for being both an asshole and micromanager. One-stop?  Sure.  Efficient?  Maybe.  Trustworthy?  Pardon me for laughing. \n",
            "\n",
            "> It's a piece of shit because every little thing you use has 3 billion dependencies which you have to validate and verify n some manner. If you mean to prevent breakage, shrinkwrap lets you lock down dependency versions:  https://docs.npmjs.com/cli/shrinkwrap If you mean something else (security?) then I'd probably just not use npm, because as you said your dependency tree is going to be deep and reviewing all of that code is impossible. \n",
            "\n",
            "That's just plain stupid. I get it, you don't want EVs to be \"tax-free\", but at least make it smaller than on gas-powered cars to encourage people to buy cleaner cars. When EVs are 50% of the market, then you can make it equal, if you think you're losing money or whatever. But such high taxes already seem extreme for any car anyway. They also eliminated the tax on NOx, even after the VW scandal. Ugh. I was wrong. This isn't stupid. Just malicious/corrupt. \n",
            "\n",
            "Is this a religious discussion now? I'm not sure that applies, anyway; ISTM that Jobs is already a dung beetle, or whatever. Besides, TFA is hardly \"seeking revenge\". The tone isn't even particularly harsh. It's just: here's some shit that dude did. \n",
            "\n",
            "I agree with the OP. Vice is pretty much a trash site. \n",
            "\n",
            "You want to throw Barney \"Roll the Dice\" Frank in jail? There tend to be lots of unintended consequences to punishing stupid politicians like that, or people outside the government following the government's prior orders. \n",
            "\n",
            "Alternately, once they realized it wasn't working, announce that the bounty would end in a month, so that the breeders would hustle to kill all their cobras and bring them in. (Or, to shift a  little  blame away from the British, maybe if the breeders hadn't been stupid/dickish enough to release a fuckload of live cobras in their neighbors' back yards.) \n",
            "\n",
            ">  These threads always fucking suck on HN. Please don't post things like that to HN. They only make threads suck worse. \n",
            "\n",
            "Edit: looking at the reading list on the site I might stop mocking the \"programming, motherfucker\" crowd. There's a lot of good works on design, analysis, and engineering techniques referenced. So, the cool, catchy line is misleading and even they will depend on Things Other Than Programming. Hope the site gets more popular. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}